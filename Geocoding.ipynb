{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import censusgeocode as cg\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using census geocode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the census geocode library to find census tracts.  You need either a street, city, and state, or a street, zipcode and state.  The return value is a list of dictionaries.  There's lots of data in the response, but we're only really interested in the census tract information.  First two digits are the state code.  Next three are the county code.  Next six are local tract identification.  The last digit is the \"block\" within the local tracts, and I forget what the remaining digits represent.  We don't need them for finding the tract data, so they'll eventually be discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "street = \"360 Beacon Street\"\n",
    "city = \"Somerville\"\n",
    "state = \"MA\"\n",
    "\n",
    "# cg.address(street = \"\",city = , state = \"\", zipcode = \"\")\n",
    "output1 = cg.address(street, city, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'250173510003004'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1[0][\"geographies\"][\"2010 Census Blocks\"][0][\"GEOID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "street = \"338 Beacon Street\"\n",
    "city = \"Somerville\"\n",
    "state = \"MA\"\n",
    "\n",
    "# cg.address(street = \"\",city = , state = \"\", zipcode = \"\")\n",
    "output2 = cg.address(street, city, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'250173510003003'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2[0][\"geographies\"][\"2010 Census Blocks\"][0][\"GEOID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function\n",
    "\n",
    "Since the output type of the geocoder contains several things, we'll use the following function to extract the census tract data.  You need to feed in a street and a city, or a street and a zipcode.  The preference is for zipcode, but city is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_address_range(geocode_data):\n",
    "    \"\"\"This is a helper function to extract the address ranges returned for a\n",
    "    geocode query.  The intent is to store the data to obviate/simplify\n",
    "    future searches.\"\"\"\n",
    "    \n",
    "    # Getting the min and max address numbers for the block found\n",
    "    fromaddress = geocode_data[0][\"addressComponents\"][\"fromAddress\"]\n",
    "    toaddress = geocode_data[0][\"addressComponents\"][\"toAddress\"]\n",
    "    \n",
    "    toaddress = geocode_data[0][\"addressComponents\"][\"toAddress\"]\n",
    "    \n",
    "    # completing the city, zipcode, and state data in case it was missing\n",
    "    city = geocode_data[0][\"addressComponents\"][\"city\"]\n",
    "    zipcode = geocode_data[0][\"addressComponents\"][\"zip\"]\n",
    "    state = geocode_data[0][\"addressComponents\"][\"state\"]\n",
    "\n",
    "    return [fromaddress, toaddress, city, zipcode, state]\n",
    "\n",
    "def extract_block(street, city = None, zipcode = None, state = \"MA\",fail = True):\n",
    "    \"\"\"This function extracts the block number for an address after passing it\n",
    "    to the census geocode function for identification.  It returns a string.  If\n",
    "    the address can't be found or is otherwise dysfunctional, the function can be\n",
    "    toggled to fail, or to return even probabilities (representing no information).\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # if the user gives the zipcode format\n",
    "        if street and zipcode:\n",
    "            # acquire the geocode response\n",
    "            output = cg.address(street = street, zipcode = zipcode, state = state)\n",
    "\n",
    "            # acquire the block number from the response\n",
    "            block_data =  output[0][\"geographies\"][\"2010 Census Blocks\"][0][\"GEOID\"]\n",
    "\n",
    "            # turn the block into the format needed for the location data lookup\n",
    "            block = block_data[:11] + block_data[-1]\n",
    "\n",
    "            # acquire the complete address data\n",
    "            address_data = extract_address_range(output)\n",
    "\n",
    "            return block, address_data\n",
    "\n",
    "        # if the user gives the city format\n",
    "        elif street and city:\n",
    "            # acquire the geocode response\n",
    "            output = cg.address(street = street, city = city, state = state)\n",
    "\n",
    "            # acquire the block number from the response\n",
    "            block_data =  output[0][\"geographies\"][\"2010 Census Blocks\"][0][\"GEOID\"]\n",
    "\n",
    "            # turn the block into the format needed for the location data lookup\n",
    "            block = block_data[:11] + block_data[-1]\n",
    "\n",
    "            # acquire the complete address data\n",
    "            address_data = extract_address_range(output)\n",
    "\n",
    "            return block, address_data\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # if the user doesn't provide enough information, or the address couldn't be found\n",
    "    # either give a failure value, None, or even probabilities if the data is cleaned\n",
    "    # properly and you assume the address just couldn't be found.\n",
    "    if fail == True:\n",
    "        return None, None\n",
    "    else:\n",
    "        return np.ones(shape = (1,6))/6, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('250173510004', ['340', '368', 'SOMERVILLE', '02143', 'MA'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, data = extract_block(street = \"350 Beacon Street\", zipcode = \"02143\")\n",
    "num, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['340', '368', 'SOMERVILLE', '02143', 'MA']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be used to compile a database to obviate censusgeocode\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file with the extra dec10 listing has absolute counts.\n",
    "loc_data = pd.read_stata(\"blkgrp_over18_race_dec10.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID10_BlkGrp</th>\n",
       "      <th>State_FIPS10</th>\n",
       "      <th>County_FIPS10</th>\n",
       "      <th>Tract_FIPS10</th>\n",
       "      <th>BlkGrp_FIPS10</th>\n",
       "      <th>Total_Pop</th>\n",
       "      <th>Hispanic_Total</th>\n",
       "      <th>Non_Hispanic_Total</th>\n",
       "      <th>NH_White_alone</th>\n",
       "      <th>NH_Black_alone</th>\n",
       "      <th>NH_AIAN_alone</th>\n",
       "      <th>NH_API_alone</th>\n",
       "      <th>NH_Other_alone</th>\n",
       "      <th>NH_Mult_Total</th>\n",
       "      <th>NH_White_Other</th>\n",
       "      <th>NH_Black_Other</th>\n",
       "      <th>NH_AIAN_Other</th>\n",
       "      <th>NH_Asian_HPI</th>\n",
       "      <th>NH_API_Other</th>\n",
       "      <th>NH_Asian_HPI_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010010201001</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>020100</td>\n",
       "      <td>1</td>\n",
       "      <td>523</td>\n",
       "      <td>13</td>\n",
       "      <td>510</td>\n",
       "      <td>441</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010010201002</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>020100</td>\n",
       "      <td>2</td>\n",
       "      <td>882</td>\n",
       "      <td>15</td>\n",
       "      <td>867</td>\n",
       "      <td>759</td>\n",
       "      <td>89</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010010202001</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>020200</td>\n",
       "      <td>1</td>\n",
       "      <td>664</td>\n",
       "      <td>23</td>\n",
       "      <td>641</td>\n",
       "      <td>218</td>\n",
       "      <td>413</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010010202002</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>020200</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>38</td>\n",
       "      <td>862</td>\n",
       "      <td>414</td>\n",
       "      <td>442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010010203001</td>\n",
       "      <td>01</td>\n",
       "      <td>001</td>\n",
       "      <td>020300</td>\n",
       "      <td>1</td>\n",
       "      <td>1859</td>\n",
       "      <td>42</td>\n",
       "      <td>1817</td>\n",
       "      <td>1460</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GEOID10_BlkGrp State_FIPS10 County_FIPS10 Tract_FIPS10 BlkGrp_FIPS10  \\\n",
       "0   010010201001           01           001       020100             1   \n",
       "1   010010201002           01           001       020100             2   \n",
       "2   010010202001           01           001       020200             1   \n",
       "3   010010202002           01           001       020200             2   \n",
       "4   010010203001           01           001       020300             1   \n",
       "\n",
       "   Total_Pop  Hispanic_Total  Non_Hispanic_Total  NH_White_alone  \\\n",
       "0        523              13                 510             441   \n",
       "1        882              15                 867             759   \n",
       "2        664              23                 641             218   \n",
       "3        900              38                 862             414   \n",
       "4       1859              42                1817            1460   \n",
       "\n",
       "   NH_Black_alone  NH_AIAN_alone  NH_API_alone  NH_Other_alone  NH_Mult_Total  \\\n",
       "0              55              4             3               0              7   \n",
       "1              89              7             6               0              6   \n",
       "2             413              1             4               1              4   \n",
       "3             442              1             1               2              2   \n",
       "4             314              5             9               0             29   \n",
       "\n",
       "   NH_White_Other  NH_Black_Other  NH_AIAN_Other  NH_Asian_HPI  NH_API_Other  \\\n",
       "0               0               0              0             0             0   \n",
       "1               0               0              0             0             0   \n",
       "2               0               0              0             0             0   \n",
       "3               0               0              0             0             0   \n",
       "4               1               0              0             2             0   \n",
       "\n",
       "   NH_Asian_HPI_Other  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID10_BlkGrp</th>\n",
       "      <th>State_FIPS10</th>\n",
       "      <th>County_FIPS10</th>\n",
       "      <th>Tract_FIPS10</th>\n",
       "      <th>BlkGrp_FIPS10</th>\n",
       "      <th>Total_Pop</th>\n",
       "      <th>Hispanic_Total</th>\n",
       "      <th>Non_Hispanic_Total</th>\n",
       "      <th>NH_White_alone</th>\n",
       "      <th>NH_Black_alone</th>\n",
       "      <th>NH_AIAN_alone</th>\n",
       "      <th>NH_API_alone</th>\n",
       "      <th>NH_Other_alone</th>\n",
       "      <th>NH_Mult_Total</th>\n",
       "      <th>NH_White_Other</th>\n",
       "      <th>NH_Black_Other</th>\n",
       "      <th>NH_AIAN_Other</th>\n",
       "      <th>NH_Asian_HPI</th>\n",
       "      <th>NH_API_Other</th>\n",
       "      <th>NH_Asian_HPI_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93108</th>\n",
       "      <td>250173510001</td>\n",
       "      <td>25</td>\n",
       "      <td>017</td>\n",
       "      <td>351000</td>\n",
       "      <td>1</td>\n",
       "      <td>1151</td>\n",
       "      <td>61</td>\n",
       "      <td>1090</td>\n",
       "      <td>946</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93109</th>\n",
       "      <td>250173510002</td>\n",
       "      <td>25</td>\n",
       "      <td>017</td>\n",
       "      <td>351000</td>\n",
       "      <td>2</td>\n",
       "      <td>595</td>\n",
       "      <td>27</td>\n",
       "      <td>568</td>\n",
       "      <td>510</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93110</th>\n",
       "      <td>250173510003</td>\n",
       "      <td>25</td>\n",
       "      <td>017</td>\n",
       "      <td>351000</td>\n",
       "      <td>3</td>\n",
       "      <td>664</td>\n",
       "      <td>33</td>\n",
       "      <td>631</td>\n",
       "      <td>472</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93111</th>\n",
       "      <td>250173510004</td>\n",
       "      <td>25</td>\n",
       "      <td>017</td>\n",
       "      <td>351000</td>\n",
       "      <td>4</td>\n",
       "      <td>1728</td>\n",
       "      <td>84</td>\n",
       "      <td>1644</td>\n",
       "      <td>1378</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93112</th>\n",
       "      <td>250173510005</td>\n",
       "      <td>25</td>\n",
       "      <td>017</td>\n",
       "      <td>351000</td>\n",
       "      <td>5</td>\n",
       "      <td>957</td>\n",
       "      <td>40</td>\n",
       "      <td>917</td>\n",
       "      <td>755</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>101</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93113</th>\n",
       "      <td>250173510006</td>\n",
       "      <td>25</td>\n",
       "      <td>017</td>\n",
       "      <td>351000</td>\n",
       "      <td>6</td>\n",
       "      <td>947</td>\n",
       "      <td>35</td>\n",
       "      <td>912</td>\n",
       "      <td>794</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GEOID10_BlkGrp State_FIPS10 County_FIPS10 Tract_FIPS10 BlkGrp_FIPS10  \\\n",
       "93108   250173510001           25           017       351000             1   \n",
       "93109   250173510002           25           017       351000             2   \n",
       "93110   250173510003           25           017       351000             3   \n",
       "93111   250173510004           25           017       351000             4   \n",
       "93112   250173510005           25           017       351000             5   \n",
       "93113   250173510006           25           017       351000             6   \n",
       "\n",
       "       Total_Pop  Hispanic_Total  Non_Hispanic_Total  NH_White_alone  \\\n",
       "93108       1151              61                1090             946   \n",
       "93109        595              27                 568             510   \n",
       "93110        664              33                 631             472   \n",
       "93111       1728              84                1644            1378   \n",
       "93112        957              40                 917             755   \n",
       "93113        947              35                 912             794   \n",
       "\n",
       "       NH_Black_alone  NH_AIAN_alone  NH_API_alone  NH_Other_alone  \\\n",
       "93108              43              0            72              10   \n",
       "93109               6              0            44               0   \n",
       "93110              24              0           125               0   \n",
       "93111              33              0           189               3   \n",
       "93112              36              7           101               8   \n",
       "93113              12              0            94               1   \n",
       "\n",
       "       NH_Mult_Total  NH_White_Other  NH_Black_Other  NH_AIAN_Other  \\\n",
       "93108             19               2               0              0   \n",
       "93109              8               0               0              0   \n",
       "93110             10               1               0              0   \n",
       "93111             41               0               0              0   \n",
       "93112             10               0               0              0   \n",
       "93113             11               2               0              0   \n",
       "\n",
       "       NH_Asian_HPI  NH_API_Other  NH_Asian_HPI_Other  \n",
       "93108             0             1                   0  \n",
       "93109             0             0                   0  \n",
       "93110             0             2                   0  \n",
       "93111             0             2                   0  \n",
       "93112             0             0                   0  \n",
       "93113             0             0                   0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '250173510003004'\n",
    "loc_data.query('State_FIPS10 == \"25\" & Tract_FIPS10 == \"351000\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_lookup(tract_id):\n",
    "    row =  loc_data.query(\"GEOID10_BlkGrp == '{}'\".format(tract_id))\n",
    "    return row.iloc[0,[8,9,11,10,13,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NH_White_alone    1378\n",
       "NH_Black_alone      33\n",
       "NH_API_alone       189\n",
       "NH_AIAN_alone        0\n",
       "NH_Mult_Total       41\n",
       "Hispanic_Total      84\n",
       "Name: 93111, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_lookup(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1378, 33, 0, 189, 3, 41, 84], dtype=object)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_convert(nums,rental = False):\n",
    "    data = np.array(nums)\n",
    "    total = np.sum(nums)\n",
    "    \n",
    "    # implement rental adjustment in the future\n",
    "    \n",
    "    return data / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7974537037037037, 0.019097222222222224, 0.0, 0.109375,\n",
       "       0.001736111111111111, 0.023726851851851853, 0.04861111111111111],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_convert(output.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surname probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sur_import = pd.read_csv(\"Names_2010Census.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has strings \"(S)\" we need to get rid of.  We use the following function to iterate over the data frame and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert needed values to floats in our imported data\n",
    "def convert(value):\n",
    "    try:\n",
    "        val = float(value)\n",
    "    except:\n",
    "        if value == \"(S)\":\n",
    "            val = 0\n",
    "        else:\n",
    "            val = value\n",
    "    return val\n",
    "\n",
    "sur_data = sur_import.applymap(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>prop100k</th>\n",
       "      <th>cum_prop100k</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctaian</th>\n",
       "      <th>pct2prace</th>\n",
       "      <th>pcthispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2442977.0</td>\n",
       "      <td>828.19</td>\n",
       "      <td>828.19</td>\n",
       "      <td>70.90</td>\n",
       "      <td>23.11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1932812.0</td>\n",
       "      <td>655.24</td>\n",
       "      <td>1483.42</td>\n",
       "      <td>58.97</td>\n",
       "      <td>34.63</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.94</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1625252.0</td>\n",
       "      <td>550.97</td>\n",
       "      <td>2034.39</td>\n",
       "      <td>45.75</td>\n",
       "      <td>47.68</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROWN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1437026.0</td>\n",
       "      <td>487.16</td>\n",
       "      <td>2521.56</td>\n",
       "      <td>57.95</td>\n",
       "      <td>35.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JONES</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1425470.0</td>\n",
       "      <td>483.24</td>\n",
       "      <td>3004.80</td>\n",
       "      <td>55.19</td>\n",
       "      <td>38.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  rank      count  prop100k  cum_prop100k  pctwhite  pctblack  \\\n",
       "0     SMITH   1.0  2442977.0    828.19        828.19     70.90     23.11   \n",
       "1   JOHNSON   2.0  1932812.0    655.24       1483.42     58.97     34.63   \n",
       "2  WILLIAMS   3.0  1625252.0    550.97       2034.39     45.75     47.68   \n",
       "3     BROWN   4.0  1437026.0    487.16       2521.56     57.95     35.60   \n",
       "4     JONES   5.0  1425470.0    483.24       3004.80     55.19     38.48   \n",
       "\n",
       "   pctapi  pctaian  pct2prace  pcthispanic  \n",
       "0    0.50     0.89       2.19         2.40  \n",
       "1    0.54     0.94       2.56         2.36  \n",
       "2    0.46     0.82       2.81         2.49  \n",
       "3    0.51     0.87       2.55         2.52  \n",
       "4    0.44     1.00       2.61         2.29  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sur_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sur_lookup(name):\n",
    "    data = sur_data.query(\"name == '{}'\".format(name.upper()))\n",
    "    nums = data.iloc[0,[5,6,7,8,9,10]].values\n",
    "    return nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.2, 53.62, 4.2, 1.05, 2.38, 3.56], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sur_lookup(\"william\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisg(name, street, city = None, zipcode = None, state = \"MA\"):\n",
    "    \n",
    "    # find the tract, extract the ethnic counts, and turn them into location probabilities\n",
    "    tract, _ = extract_block(street, city, zipcode, state)\n",
    "    loc_nums = loc_lookup(tract)\n",
    "    loc_probs = prob_convert(loc_nums)\n",
    "    \n",
    "    # find the sur_name counts, and turn them into surname probabilities\n",
    "    sur_nums = sur_lookup(name)\n",
    "    print(sur_nums)\n",
    "    sur_probs = prob_convert(sur_nums)\n",
    "    \n",
    "    # combine the probabilities, and scale them to have probability 1\n",
    "    joint = sur_probs * loc_probs\n",
    "    marginal = np.sum(joint)\n",
    "    post = joint / marginal\n",
    "    \n",
    "    # probabilities for white, black, API, AIAN, Multi-racial, and hispanic, in that order.\n",
    "    bisg_probs = post\n",
    "    \n",
    "    return bisg_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77.84 12.25 0.78 1.34 1.67 6.12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9895364977166499, 0.003729321293967937, 0.0013599914536963596,\n",
       "       0.0, 0.000631655235616536, 0.004742534300069356], dtype=object)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bisg(name = \"palin\", street = \"350 Beacon Street\", city = \"Somerville\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
